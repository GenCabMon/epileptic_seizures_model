# Detección de episodios epilépticos en pacientes de 3 a 12 años mediante el análisis de EEGs con un sistema clasificador basado en técnicas de inteligencia computacional 
La base de datos utilizada para este proyecto contiene segmentos de EEG medidos durante un tiempo determinado, para los cuales se registra inicio y finalización de un episodio epiléptico, en dado caso que haya sucedido. Debido a que el desarrollo cerebral de la persona comprende un factor importante al analizar este tipo de enfermedad neurológica, nos enfocaremos solo en pacientes en su etapa de niñez (3 a 12 años), para un total de 15 sujetos de los 24 que se encuentran en la base de datos adjunta. Para la extracción de características, se encontró que normalmente se analizan la amplitud, frecuencia y morfología del segmento. Lo cual juega un rol crucial para definir los procesos involucrados en la etapa de preprocesamiento de las señales EEG, y será explicado con mayor detalle más adelante.

Para un tratamiento menos complejo de los datos se decidió el uso de 23 canales de señales EEG (Especificados en 'channel_names' más adelante), de modo que se debe verificar que todos los pacientes incluidos dentro de este estudio posean estos 23 canales y eliminar aquellos canales que no se encuentren incluidos. Aquellos segmentos de EEG que no registren alguno de los 23 canales especificados deben eliminarse de la base de datos debido a que dificultan el posterior análisis de características de las señales.

Como primer acercamiento, se seleccionaron únicamente los segmentos de EEG que contienen tanto periodos interictales (Intervalos de tiempo sin crisis epiléptica) como ictales (Intervalos de tiempo con crisis epilépticas activas) de los pacientes y según si es necesario posteriormente durante el entrenamiento y validación del modelo de ML, se decide si es necesaria la incorporación de los segmentos de EEG que sólo contienen periodos interictales con el fin de proporcionar mayor cantidad de datos.

Así, el objetivo final de este proyecto corresponde a la implementación de un sistema clasificador de periodos interictales e ictales en pacientes con epilepsia entre los 3 a 12 años mediante el análisis de segmentos de EEG basándose en técnicas de inteligencia computacional.
## Definición de centro de estudio del proyecto
Primero, definimos los 23 canales de cada segmento de EEG de cada paciente que vamos a analizar.

Cabe destacar que los nombres de los canales están dispuestos de modo que se agrupan como derivaciones EEG que corresponden a la diferencia de mediciones de pares de electrodos para contrarrestar artefactos y ruido en las señales resultantes. Además, esto permite resaltar cambios eléctricos locales, como actividad epileptiforme o ritmos específicos (Ondas alpha, beta, miu, etc).
## Preprocesamiento de características
En esta primera fase, se realiza una primera etapa de reducción de dimensionalidad de la base de datos. En primer lugar, se identifican los archivos con una tasa de muestreo diferente a 256 Hz para su remuestreo de ser mayores a este valor, y ser descartados en dado caso de poseer una tasa de muestreo inferior a este valor. En segundo lugar, se realiza la eliminación de aquellos canales de los segmentos de EEG que se encuentran repetidos con el fin de facilitar la lectura de los archivos edf.
## Procesamiento de características
En este punto ya se tienen entonces las ventanas de tiempo con duración de 1 segundo cada una, para las clases 'Ictal' e 'Interictal'. Ahora, para una primera extracción de características, se utiliza una TDWM de 3 niveles de tipo Daubechies, con el objetivo de redistribuir los datos contenidos en las ventanas entre las 4 subbandas siguientes: D1, D2, D3 y A3. Donde D1 a D3 contienen los datos de bajas frecuencias y A3 los datos de altas frecuencias. Al solo comprender una redistribución de las muestras de cada ventana, se debe aclarar que no corresponde a las características que se van a tener en cuenta para la clasificación de ventanas de tiempo.
A partir de una serie de tests estadísticos se busca identificar aquellas características (Test Kolmogorov - Smirnov seguido de test de Mann - Whitney U) con mayor relevancia, para posteriormente, con ayuda de la implementación de una SFBS, identificara el conjunto de características que mejora el rendimiento del modelo (Evaluado con métrica de desempeño F1 - Macro). Finalmente, a partir de este conjunto de características se realiza una extracción de nuevas características con PCA para reducir la dimensionalidad de las muestras con una varianza de los datos superior al 90%.
## Implementación de modelos de ML
La partición de los datos en conjunto de entrenamiento y prueba se desarrolló a modo de interpolación estratificada de los datos en una proporción 70 - 30, es decir, garantizando que las proporciones de datos fueran adecuadamente distribuidas para cada clase en los dos conjuntos generados. Además, se realizó esta partición de modo que se garantizara que los datos pertenecientes a un mismo paciente sólo fuesen usados en uno de los conjuntos de datos. Esto con el propósito de analizar la capacidad de los modelos de Machine Learning para la identificación de eventos ictales de pacientes no considerados en su entrenamiento, dando una perspectiva más realista para la viabilidad de uso de uno de estos modelos. 
Se realizaron pruebas de desempeño con modelos de Regresión Logística, Random Forest, SVM y RNA (Backpropagation) de tal manera que, en la búsqueda de sus correspondientes hiperparámetros se priorizara, en una primera etapa, la exactitud (Accuracy) del modelo, y, en una segunda etapa de búsqueda, el recall de la clase Ictal. Además, se hicieron pruebas de desempeño para cada modelo tanto con la implementación de datos sintéticos (SMOTE) como sin ella, así como con y sin el uso de PCA en el conjunto de características guardadas.
## Conclusiones
En cuanto al rendimiento de los modelos, observamos que la exactitud fue superior sin emplear la técnica de reducción de dimensionalidad (PCA). Al seleccionar los parámetros más adecuados y experimentar con variaciones de los modelos de ML, tanto con datos sintéticos como sin ellos, logramos una exactitud muy competente, alineada con las recomendaciones de los autores. Además, aun sin aplicar una arquitectura SIP o SDP (Spatially Independent/Dependent Processing), alcanzamos un recall diferenciador que nos permite detectar eventos clínicamente críticos.

Ahora del análsis del tablas nos encontramos que:

* La SVM sin SMOTE ni PCA alcanzó la mayor exactitud (83 %), lo que indica que es la más fiable a la hora de asignar correctamente las etiquetas en promedio.

* El Random Forest sin SMOTE ni PCA consiguió el mejor recall Ictal (69 %), lo que la convierte en la opción más efectiva para detectar verdaderamente los eventos críticos (minimizando los falsos negativos).

Entonces podemos que decir que, si objetivo principal es maximizar la exactitud general, la SVM es la más adecuada; pero si priorizamos la detección de todos los eventos críticos, el Random Forest resulta más robusto.